{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Crawl tweets by API"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# ! pip install tqdm\n",
    "# ! pip install tweepy\n",
    "# ! pip install torch\n",
    "# ! pip install transformers\n",
    "# ! pip install emoji"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# https://github.com/twitterdev/Twitter-API-v2-sample-code/blob/main/Tweet-Lookup/get_tweets_with_bearer_token.py\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# To set your bearer token:\n",
    "bearer_token = \"AAAAAAAAAAAAAAAAAAAAAGdZbgEAAAAAlXMiIg%2F96Ygnv%2FmvFDMsWb6LuSw%3DPTSIRz5g0G9RaB9pxp8QhdTtHxXnhEZsjLkpNyqQBR8EfRy8WS\"\n",
    "\n",
    "\n",
    "def create_url(ids):\n",
    "    tweet_fields = \"tweet.fields=attachments,author_id,context_annotations,conversation_id,created_at,entities,geo,id,in_reply_to_user_id,lang,public_metrics,possibly_sensitive,referenced_tweets,reply_settings,source,text,withheld\"\n",
    "    # Tweet fields are adjustable.\n",
    "    # Options include:\n",
    "    # attachments, author_id, context_annotations,\n",
    "    # conversation_id, created_at, entities, geo, id,\n",
    "    # in_reply_to_user_id, lang, non_public_metrics, organic_metrics,\n",
    "    # possibly_sensitive, promoted_metrics, public_metrics, referenced_tweets,\n",
    "    # source, text, and withheld\n",
    "    ids = \"ids=\" + ids\n",
    "    # print(ids)\n",
    "    # You can adjust ids to include a single Tweets.\n",
    "    # Or you can add to up to 100 comma-separated IDs\n",
    "    url = \"https://api.twitter.com/2/tweets?{}&{}\".format(ids, tweet_fields)\n",
    "    return url\n",
    "\n",
    "\n",
    "def bearer_oauth(r):\n",
    "    \"\"\"\n",
    "    Method required by bearer token authentication.\n",
    "    \"\"\"\n",
    "    r.headers[\"Authorization\"] = f\"Bearer {bearer_token}\"\n",
    "    r.headers[\"User-Agent\"] = \"v2TweetLookupPython\"\n",
    "    return r\n",
    "\n",
    "\n",
    "def connect_to_endpoint(url):\n",
    "    response = requests.request(\"GET\", url, auth=bearer_oauth)\n",
    "    # print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    return response.json()\n",
    "\n",
    "\n",
    "def crawl_and_save(f_in, f_out):\n",
    "    train_id_list = []\n",
    "    for l in f_in.readlines():\n",
    "        train_id_list.extend(l.strip().split(\",\"))\n",
    "    start_id = 0\n",
    "    end_id = start_id + 100\n",
    "    train_id_len = len(train_id_list)\n",
    "    # max 100 tweet\n",
    "    split_crawl = []\n",
    "    while start_id < train_id_len:\n",
    "        split_crawl.append(\",\".join(train_id_list[start_id:end_id]))\n",
    "        start_id = end_id\n",
    "        end_id = start_id + 100\n",
    "\n",
    "    crawl_count = 0\n",
    "    for ids in tqdm(split_crawl):\n",
    "        url = create_url(ids)\n",
    "        json_response = connect_to_endpoint(url)\n",
    "        for x in json_response[\"data\"]:\n",
    "            json.dump(x, open(f_out + str(x[\"id\"]) + \".json\", \"w\"))\n",
    "        crawl_count += 1\n",
    "        if crawl_count % 290 == 0:\n",
    "            time.sleep(790)\n",
    "\n",
    "# un-comment to crawl tweets\n",
    "def main():\n",
    "    print(\"crawl the train tweets\")\n",
    "    #crawl_and_save(open(\"data/train.data.txt\", \"r\"), \"data/train_tweet/\")\n",
    "    # print(\"crawl the dev tweets\")\n",
    "    # crawl_and_save(open(\"data/dev.data.txt\", \"r\"), \"data/dev_tweet/\")\n",
    "    # print(\"crawl the analysis tweets\")\n",
    "    # crawl_and_save(open(\"data/covid.data.txt\", \"r\"), \"data/analysis_tweet/\")\n",
    "    print(\"Finished!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Dataset read-in"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read-in tweets and labels, then sort one tweet with retweets by time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "train_ids = open(\"data/train.data.txt\", \"r\")\n",
    "train_labels = open(\"data/train.label.txt\", \"r\")\n",
    "dev_ids = open(\"data/dev.data.txt\", \"r\")\n",
    "dev_labels = open(\"data/dev.label.txt\", \"r\")\n",
    "\n",
    "def read_ids_labels(ids, labels, test = False):\n",
    "    train_set = []\n",
    "    train_label = []\n",
    "    for train_ids_str, label in zip(ids.readlines(), labels.readlines()):\n",
    "        train_ids_list = train_ids_str.strip().split(\",\")\n",
    "        temp_json_list = []\n",
    "        if os.path.exists(\"data/train_tweet/\" + train_ids_list[0] + \".json\"):\n",
    "            for train_id in train_ids_list:\n",
    "                train_path = \"data/train_tweet/\" + train_id + \".json\"\n",
    "                if os.path.exists(train_path):\n",
    "                    temp_json_list.append(json.load(open(train_path, \"r\")))\n",
    "        # sort according to time\n",
    "        temp_json_list = sorted(temp_json_list, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], '%Y-%m-%dT%H:%M:%S.%fZ')))\n",
    "        train_set.append(temp_json_list)\n",
    "        if label.strip() == \"rumour\":\n",
    "            train_label.append(1)\n",
    "        else:\n",
    "            train_label.append(0)\n",
    "\n",
    "    return train_set, train_label\n",
    "\n",
    "train_set, train_label = read_ids_labels(train_ids, train_labels)\n",
    "dev_set, dev_label = read_ids_labels(dev_ids, dev_labels)\n",
    "print(\"Finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entities': {'urls': [{'start': 87, 'end': 110, 'url': 'https://t.co/q133xXBiwl', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250219116993974272/photo/1', 'display_url': 'pic.twitter.com/q133xXBiwl'}], 'hashtags': [{'start': 70, 'end': 86, 'tag': 'COVID19Malaysia'}]}, 'id': '1250219116993974272', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '30', 'name': 'Entities [Entity Service]', 'description': 'Entity Service top level domain, every item that is in Entity Service should be in this domain'}, 'entity': {'id': '825047692124442624', 'name': 'Food', 'description': 'Food'}}, {'domain': {'id': '30', 'name': 'Entities [Entity Service]', 'description': 'Entity Service top level domain, every item that is in Entity Service should be in this domain'}, 'entity': {'id': '824777229892661248', 'name': 'Generic Food', 'description': 'Generic Food'}}, {'domain': {'id': '30', 'name': 'Entities [Entity Service]', 'description': 'Entity Service top level domain, every item that is in Entity Service should be in this domain'}, 'entity': {'id': '842797798626009088', 'name': 'Vegetable recipes', 'description': 'Vegetables'}}], 'referenced_tweets': [{'type': 'replied_to', 'id': '1250218948701769728'}], 'lang': 'en', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'text': '4. Can eating garlic help prevent infection with the new coronavirus? #COVID19Malaysia https://t.co/q133xXBiwl', 'conversation_id': '1250217682533642240', 'attachments': {'media_keys': ['3_1250219081166254081']}, 'source': 'Twitter Web App', 'created_at': '2020-04-15T00:27:20.000Z', 'in_reply_to_user_id': '312362691', 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250219300389974016', 'text': '5. Can regularly rinsing your nose with saline help prevent infection with the new coronavirus? https://t.co/ccMjhhD7BK', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 96, 'end': 119, 'url': 'https://t.co/ccMjhhD7BK', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250219300389974016/photo/1', 'display_url': 'pic.twitter.com/ccMjhhD7BK'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250219116993974272'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:28:03.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250219288406810624']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250219437027766273', 'text': '6. Do vaccines against pneumonia protect you against the new coronavirus? https://t.co/wL0mlEqU95', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 74, 'end': 97, 'url': 'https://t.co/wL0mlEqU95', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250219437027766273/photo/1', 'display_url': 'pic.twitter.com/wL0mlEqU95'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250219300389974016'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:28:36.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250219431004745729']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'entities': {'hashtags': [{'start': 81, 'end': 89, 'tag': 'Chamber'}], 'urls': [{'start': 90, 'end': 113, 'url': 'https://t.co/zunVR7Ht0V', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250219620939657216/photo/1', 'display_url': 'pic.twitter.com/zunVR7Ht0V'}]}, 'id': '1250219620939657216', 'text': '7. Can spraying alcohol or chlorine all over your body kill the new coronavirus? #Chamber https://t.co/zunVR7Ht0V', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250219437027766273'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:29:20.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250219494405844992']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250219777185873922', 'text': '8. How effective are thermal scanners in detecting people infected with the new coronavirus? https://t.co/nyLOyKAb1H', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 93, 'end': 116, 'url': 'https://t.co/nyLOyKAb1H', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250219777185873922/photo/1', 'display_url': 'pic.twitter.com/nyLOyKAb1H'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250219620939657216'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:29:57.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250219766691708928']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250219894429208577', 'text': '9. Can an ultraviolet disinfection lamp kill the new coronavirus? https://t.co/ZrlllbkIjm', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 66, 'end': 89, 'url': 'https://t.co/ZrlllbkIjm', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250219894429208577/photo/1', 'display_url': 'pic.twitter.com/ZrlllbkIjm'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250219777185873922'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:30:25.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250219886543953922']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250219998842216448', 'text': '10. Are hand dryers effective in killing the new coronavirus? https://t.co/cSDKXO1bGr', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 62, 'end': 85, 'url': 'https://t.co/cSDKXO1bGr', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250219998842216448/photo/1', 'display_url': 'pic.twitter.com/cSDKXO1bGr'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250219894429208577'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:30:50.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250219939102769157']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250220115762667520', 'text': '11. The new coronavirus CANNOT be transmitted through mosquito bites. https://t.co/ZRL8bjRkpl', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 70, 'end': 93, 'url': 'https://t.co/ZRL8bjRkpl', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250220115762667520/photo/1', 'display_url': 'pic.twitter.com/ZRL8bjRkpl'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250219998842216448'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:31:18.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250220108611379200']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250220272306638848', 'text': '12. Taking a hot bath does not prevent the new coronavirus disease https://t.co/bICOqSTOuD', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 67, 'end': 90, 'url': 'https://t.co/bICOqSTOuD', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250220272306638848/photo/1', 'display_url': 'pic.twitter.com/bICOqSTOuD'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250220115762667520'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:31:55.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250220258423484416']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '30', 'name': 'Entities [Entity Service]', 'description': 'Entity Service top level domain, every item that is in Entity Service should be in this domain'}, 'entity': {'id': '854692455005921281', 'name': 'Science', 'description': 'Science'}}, {'domain': {'id': '66', 'name': 'Interests and Hobbies Category', 'description': 'A grouping of interests and hobbies entities, like Novelty Food or Destinations'}, 'entity': {'id': '857083369514876928', 'name': 'Weather', 'description': 'Weather'}}, {'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250220389323526146', 'text': '13. Cold weather and snow CANNOT kill the new coronavirus. https://t.co/7yeQQ6gLNo', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 59, 'end': 82, 'url': 'https://t.co/7yeQQ6gLNo', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250220389323526146/photo/1', 'display_url': 'pic.twitter.com/7yeQQ6gLNo'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250220272306638848'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:32:23.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250220381903843328']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '29', 'name': 'Events [Entity Service]', 'description': 'Entity Service related Events domain'}, 'entity': {'id': '1219057585707315201', 'name': 'COVID-19: Latest news updates from around the world', 'description': 'This page is a timeline of Tweets with the latest information and updates on COVID-19 from experts, journalists, health authorities and other trusted sources from around the world. For more on COVID-19, visit: twitter.com/explore/tabs/covid-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250220527005753344', 'text': '14. COVID-19 virus can be transmitted in areas with hot and humid climates https://t.co/ylKa2F40vu', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 75, 'end': 98, 'url': 'https://t.co/ylKa2F40vu', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250220527005753344/photo/1', 'display_url': 'pic.twitter.com/ylKa2F40vu'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250220389323526146'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:32:56.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250220519367966721']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '65', 'name': 'Interests and Hobbies Vertical', 'description': 'Top level interests and hobbies groupings, like Food or Travel'}, 'entity': {'id': '834828264786898945', 'name': 'Drinks', 'description': 'Drinks'}}, {'domain': {'id': '67', 'name': 'Interests and Hobbies', 'description': 'Interests, opinions, and behaviors of individuals, groups, or cultures; like Speciality Cooking or Theme Parks'}, 'entity': {'id': '1006278636842782720', 'name': 'Drink Experience', 'description': 'Drink Experience'}}, {'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250220791544705025', 'text': '15. Drinking alcohol does not protect you against COVID-19 and can be dangerous https://t.co/ZrLN61q046', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 80, 'end': 103, 'url': 'https://t.co/ZrLN61q046', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250220791544705025/photo/1', 'display_url': 'pic.twitter.com/ZrLN61q046'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250220527005753344'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:33:59.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250220784812830720']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '29', 'name': 'Events [Entity Service]', 'description': 'Entity Service related Events domain'}, 'entity': {'id': '1219057585707315201', 'name': 'COVID-19: Latest news updates from around the world', 'description': 'This page is a timeline of Tweets with the latest information and updates on COVID-19 from experts, journalists, health authorities and other trusted sources from around the world. For more on COVID-19, visit: twitter.com/explore/tabs/covid-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250220987238383616', 'text': '16. Being able to hold your breath for 10 seconds or more without coughing or feeling discomfort DOES NOT mean you are free from the coronavirus disease (COVID-19) or any other lung disease. https://t.co/gPUL51Y2lx', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 191, 'end': 214, 'url': 'https://t.co/gPUL51Y2lx', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250220987238383616/photo/1', 'display_url': 'pic.twitter.com/gPUL51Y2lx'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250220791544705025'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:34:45.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250220971400654849']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '29', 'name': 'Events [Entity Service]', 'description': 'Entity Service related Events domain'}, 'entity': {'id': '1219057585707315201', 'name': 'COVID-19: Latest news updates from around the world', 'description': 'This page is a timeline of Tweets with the latest information and updates on COVID-19 from experts, journalists, health authorities and other trusted sources from around the world. For more on COVID-19, visit: twitter.com/explore/tabs/covid-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250221140603047937', 'text': '17. You can recover from the coronavirus disease (COVID-19). Catching the new coronavirus DOES NOT mean you will have it for life. https://t.co/yrjUM5qniK', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 131, 'end': 154, 'url': 'https://t.co/yrjUM5qniK', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250221140603047937/photo/1', 'display_url': 'pic.twitter.com/yrjUM5qniK'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250220987238383616'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:35:22.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250221134303260672']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 1, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '29', 'name': 'Events [Entity Service]', 'description': 'Entity Service related Events domain'}, 'entity': {'id': '1219057585707315201', 'name': 'COVID-19: Latest news updates from around the world', 'description': 'This page is a timeline of Tweets with the latest information and updates on COVID-19 from experts, journalists, health authorities and other trusted sources from around the world. For more on COVID-19, visit: twitter.com/explore/tabs/covid-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250221275827470336', 'text': '18. Exposing yourself to the sun or to temperatures higher than 25C degrees DOES NOT prevent the coronavirus disease (COVID-19) https://t.co/aOQKrrwaBv', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 128, 'end': 151, 'url': 'https://t.co/aOQKrrwaBv', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250221275827470336/photo/1', 'display_url': 'pic.twitter.com/aOQKrrwaBv'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250221140603047937'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:35:54.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250221260648243200']}, 'author_id': '312362691'}, {'public_metrics': {'retweet_count': 0, 'reply_count': 0, 'like_count': 0, 'quote_count': 0}, 'source': 'Twitter Web App', 'context_annotations': [{'domain': {'id': '30', 'name': 'Entities [Entity Service]', 'description': 'Entity Service top level domain, every item that is in Entity Service should be in this domain'}, 'entity': {'id': '1085628093627195392', 'name': '5G', 'description': '5G'}}, {'domain': {'id': '123', 'name': 'Ongoing News Story', 'description': \"Ongoing News Stories like 'Brexit'\"}, 'entity': {'id': '1220701888179359745', 'name': 'COVID-19'}}, {'domain': {'id': '29', 'name': 'Events [Entity Service]', 'description': 'Entity Service related Events domain'}, 'entity': {'id': '1219057585707315201', 'name': 'COVID-19: Latest news updates from around the world', 'description': 'This page is a timeline of Tweets with the latest information and updates on COVID-19 from experts, journalists, health authorities and other trusted sources from around the world. For more on COVID-19, visit: twitter.com/explore/tabs/covid-19'}}], 'conversation_id': '1250217682533642240', 'id': '1250221402822545410', 'text': '19. 5G mobile networks DO NOT spread COVID-19 https://t.co/VjqelBmpTn', 'reply_settings': 'everyone', 'possibly_sensitive': False, 'entities': {'urls': [{'start': 46, 'end': 69, 'url': 'https://t.co/VjqelBmpTn', 'expanded_url': 'https://twitter.com/ucoptempe/status/1250221402822545410/photo/1', 'display_url': 'pic.twitter.com/VjqelBmpTn'}]}, 'referenced_tweets': [{'type': 'replied_to', 'id': '1250221275827470336'}], 'in_reply_to_user_id': '312362691', 'created_at': '2020-04-15T00:36:25.000Z', 'lang': 'en', 'attachments': {'media_keys': ['3_1250221329959116800']}, 'author_id': '312362691'}]\n"
     ]
    }
   ],
   "source": [
    "print(train_set[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "# read in test data\n",
    "test_ids = open(\"data/test.data.txt\", \"r\")\n",
    "test_set = []\n",
    "for test_ids_str in test_ids.readlines():\n",
    "    test_ids_list = test_ids_str.strip().split(\",\")\n",
    "    temp_json_list = []\n",
    "    for test_id in test_ids_list:\n",
    "        test_path = \"data/tweet-objects/\" + test_id + \".json\"\n",
    "        if os.path.exists(test_path):\n",
    "            temp_json_list.append(json.load(open(test_path, \"r\")))\n",
    "\n",
    "    # sort according to time\n",
    "    temp_json_list = sorted(temp_json_list, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], '%a %b %d %H:%M:%S +0000 %Y')))\n",
    "    # temp_json_list = sorted(temp_json_list, key=lambda x: time.mktime(time.strptime(x[\"created_at\"], '%Y-%m-%dT%H:%M:%S.%fZ')))\n",
    "    test_set.append(temp_json_list)\n",
    "\n",
    "print(\"Finished!\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Try to use workshop 10 bert model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-covid19-base-uncased were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModel, AutoTokenizer\n",
    "from transformers import AdamW\n",
    "import torch\n",
    "pre_trained_weights = \"vinai/bertweet-covid19-base-uncased\"\n",
    "bertweet = AutoModel.from_pretrained(pre_trained_weights)\n",
    "tokenizer = AutoTokenizer.from_pretrained(pre_trained_weights, normalization=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Combine a tweet and its retweets into one string"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "def combine_tweet_retweet(train_set):\n",
    "    all_tweets = []\n",
    "\n",
    "    for tweets in train_set:\n",
    "        tweets_list = []\n",
    "        for tweet in tweets:\n",
    "            text = tweet[\"text\"]\n",
    "            text_list = []\n",
    "            # replace @user and http\n",
    "            for word in text.split(\" \"):\n",
    "                if len(word) > 1 and word[0] == \"@\":\n",
    "                    text_list.append(\"@USER\")\n",
    "                elif len(word) > 4 and word[0:4] == \"http\":\n",
    "                    text_list.append(\"HTTPURL\")\n",
    "                else:\n",
    "                    text_list.append(word)\n",
    "            new_text = \" \".join(text_list)\n",
    "            tweets_list.append(new_text)\n",
    "        all_tweets.append(tokenizer.sep_token.join(tweets_list))\n",
    "\n",
    "    return all_tweets\n",
    "\n",
    "train_text = combine_tweet_retweet(train_set)\n",
    "dev_text = combine_tweet_retweet(dev_set)\n",
    "test_text = combine_tweet_retweet(test_set)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "'4. Can eating garlic help prevent infection with the new coronavirus? #COVID19Malaysia HTTPURL</s>5. Can regularly rinsing your nose with saline help prevent infection with the new coronavirus? HTTPURL</s>6. Do vaccines against pneumonia protect you against the new coronavirus? HTTPURL</s>7. Can spraying alcohol or chlorine all over your body kill the new coronavirus? #Chamber HTTPURL</s>8. How effective are thermal scanners in detecting people infected with the new coronavirus? HTTPURL</s>9. Can an ultraviolet disinfection lamp kill the new coronavirus? HTTPURL</s>10. Are hand dryers effective in killing the new coronavirus? HTTPURL</s>11. The new coronavirus CANNOT be transmitted through mosquito bites. HTTPURL</s>12. Taking a hot bath does not prevent the new coronavirus disease HTTPURL</s>13. Cold weather and snow CANNOT kill the new coronavirus. HTTPURL</s>14. COVID-19 virus can be transmitted in areas with hot and humid climates HTTPURL</s>15. Drinking alcohol does not protect you against COVID-19 and can be dangerous HTTPURL</s>16. Being able to hold your breath for 10 seconds or more without coughing or feeling discomfort DOES NOT mean you are free from the coronavirus disease (COVID-19) or any other lung disease. HTTPURL</s>17. You can recover from the coronavirus disease (COVID-19). Catching the new coronavirus DOES NOT mean you will have it for life. HTTPURL</s>18. Exposing yourself to the sun or to temperatures higher than 25C degrees DOES NOT prevent the coronavirus disease (COVID-19) HTTPURL</s>19. 5G mobile networks DO NOT spread COVID-19 HTTPURL'"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "class TweetDataset(Dataset):\n",
    "    def __init__(self, tweet_list, label_list, tokenizer):\n",
    "        self.tweet_list = tweet_list\n",
    "        self.label_list = label_list\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweet_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tweet_list[idx], self.label_list[idx]\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        tweets = []\n",
    "        labels = []\n",
    "        for text, label in data:\n",
    "            tweets.append(text)\n",
    "            labels.append(label)\n",
    "        tokens = self.tokenizer(tweets, max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        data_dict = {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"attn_mask\": tokens[\"attention_mask\"],\n",
    "        \"label\": torch.tensor(labels).long()\n",
    "        }\n",
    "        return data_dict\n",
    "\n",
    "train_set = TweetDataset(train_text, train_label, tokenizer)\n",
    "dev_set = TweetDataset(dev_text, dev_label, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "class testDataset(Dataset):\n",
    "    def __init__(self, tweet_list, tokenizer):\n",
    "        self.tweet_list = tweet_list\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tweet_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tweet_list[idx]\n",
    "\n",
    "    def collate_fn(self, data):\n",
    "        tweets = []\n",
    "        for text in data:\n",
    "            tweets.append(text)\n",
    "        tokens = self.tokenizer(tweets, max_length=512, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "        data_dict = {\n",
    "        \"input_ids\": tokens[\"input_ids\"],\n",
    "        \"attn_mask\": tokens[\"attention_mask\"]\n",
    "        }\n",
    "        return data_dict\n",
    "\n",
    "test_set = testDataset(test_text, tokenizer)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "creat cls model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at vinai/bertweet-covid19-base-uncased were not used when initializing RobertaModel: ['lm_head.dense.bias', 'lm_head.layer_norm.bias', 'lm_head.bias', 'lm_head.decoder.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "from transformers import AutoModel\n",
    "\n",
    "\n",
    "class RumourCLS(nn.Module):\n",
    "    def __init__(self, pre_encoder):\n",
    "\n",
    "        super(RumourCLS, self).__init__()\n",
    "        self.encoder = AutoModel.from_pretrained(pre_encoder)\n",
    "        hidden_size = self.encoder.config.hidden_size\n",
    "        self.cls = nn.Linear(hidden_size, 2)\n",
    "\n",
    "    def forward(self, reps, masks):\n",
    "        texts_emb = self.encoder(input_ids=reps, attention_mask=masks).last_hidden_state\n",
    "        # first token\n",
    "        texts_emb = texts_emb[:, 0, :]\n",
    "        logits = self.cls(texts_emb)\n",
    "\n",
    "        return logits\n",
    "\n",
    "RumourCLS = RumourCLS(pre_trained_weights)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from transformers.optimization import get_cosine_schedule_with_warmup\n",
    "from transformers import AdamW\n",
    "from pytorch_lightning import LightningModule\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "\n",
    "class RumourDetection(LightningModule):\n",
    "    def __init__(self, pre_trained_weights):\n",
    "\n",
    "        \"\"\"Initialize model and tokenizer.\"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pre_trained_weights)\n",
    "        self.cls = RumourCLS(pre_trained_weights)\n",
    "\n",
    "        self.output_dir = Path(\"modelData\")\n",
    "        self.metrics_save_path = Path(self.output_dir) / \"metrics.json\"\n",
    "        self.metrics = dict()\n",
    "        self.metrics[\"val\"] = []\n",
    "        self.val_metric = \"f1_score\"\n",
    "\n",
    "        # -1 mean use all\n",
    "        n_observations_per_split = {\n",
    "            \"train\": -1,\n",
    "            \"val\": -1,\n",
    "            \"test\": -1,\n",
    "        }\n",
    "        self.n_obs = {k: v if v >= 0 else None for k, v in n_observations_per_split.items()}\n",
    "\n",
    "    def re_init(self):\n",
    "\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(pre_trained_weights)\n",
    "\n",
    "        self.output_dir = Path(\"modelData\")\n",
    "        self.metrics_save_path = Path(self.output_dir) / \"metrics.json\"\n",
    "        self.metrics = dict()\n",
    "        self.metrics[\"val\"] = []\n",
    "        self.val_metric = \"f1_score\"\n",
    "\n",
    "        n_observations_per_split = {\n",
    "            \"train\": -1,\n",
    "            \"val\": -1,\n",
    "            \"test\": -1,\n",
    "        }\n",
    "        self.n_obs = {k: v if v >= 0 else None for k, v in n_observations_per_split.items()}\n",
    "\n",
    "    def total_steps(self) -> int:\n",
    "        \"\"\"The number of total training steps that will be run. Used for lr scheduler purposes.\"\"\"\n",
    "        return (len(self.train_dataloader().dataset) / 16) * 100\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"\"\"Prepare Adafactor optimizer and schedule\"\"\"\n",
    "        no_decay = ['bias', 'LayerNorm.weight']\n",
    "        encoder_parameters = [\n",
    "            {'params': [p for n, p in self.cls.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 1e-3},\n",
    "            {'params': [p for n, p in self.cls.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "             'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "        encoder_optimizer = AdamW(encoder_parameters, lr=5e-5)\n",
    "\n",
    "        total_steps = int(self.total_steps())\n",
    "        encoder_scheduler = get_cosine_schedule_with_warmup(encoder_optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps)\n",
    "        encoder_scheduler = {\"scheduler\": encoder_scheduler, \"interval\": \"step\", \"frequency\": 1}\n",
    "        return [encoder_optimizer], [encoder_scheduler]\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        logits = self.cls(batch[\"input_ids\"], batch[\"attn_mask\"])\n",
    "        labels = batch[\"label\"]\n",
    "        loss = torch.nn.functional.cross_entropy(logits, labels)\n",
    "        if batch_idx % 20 == 0:\n",
    "            self.logger.log_metrics({\"loss\": loss.item()})\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        logits = self.cls(batch[\"input_ids\"], batch[\"attn_mask\"])\n",
    "        preds = torch.argmax(logits, dim=1).tolist()\n",
    "        labels = batch[\"label\"]\n",
    "        return {\"preds\": preds, \"labels\": labels.tolist()}\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        logits = self.cls(batch[\"input_ids\"], batch[\"attn_mask\"])\n",
    "        preds = torch.argmax(logits, dim=1).tolist()\n",
    "        return {\"preds\": preds}\n",
    "\n",
    "    def get_dataloader(self, type_path, batch_size, shuffle=False):\n",
    "        n_obs = self.n_obs[type_path]\n",
    "        if type_path == \"train\":\n",
    "            dataset = train_set\n",
    "            return DataLoader(dataset,batch_size=batch_size,collate_fn=dataset.collate_fn,shuffle=True,\n",
    "                              num_workers=16,sampler=None,drop_last=True)\n",
    "        elif type_path == \"val\":\n",
    "            dataset = dev_set\n",
    "            return DataLoader(dataset,batch_size=batch_size,collate_fn=dataset.collate_fn,shuffle=shuffle,\n",
    "                              num_workers=16,sampler=None)\n",
    "        else:\n",
    "            dataset = test_set\n",
    "            return DataLoader(\n",
    "                dataset,\n",
    "                batch_size=batch_size,\n",
    "                collate_fn=dataset.collate_fn,\n",
    "                shuffle=shuffle,\n",
    "                num_workers=16,\n",
    "                sampler=None,\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return self.get_dataloader(\"train\", batch_size=16, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.get_dataloader(\"val\", batch_size=16)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.get_dataloader(\"test\", batch_size=16)\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        preds = []\n",
    "        labels = []\n",
    "        for x in outputs:\n",
    "            for pred, label in zip(x[\"preds\"], x[\"labels\"]):\n",
    "                preds.append(pred)\n",
    "                labels.append(label)\n",
    "\n",
    "        p, r, f, _ = precision_recall_fscore_support(labels, preds, pos_label=1, average=\"binary\")\n",
    "        self.log(self.val_metric, f, logger=False)\n",
    "\n",
    "        val_metrics = dict()\n",
    "        val_metrics[f\"val_precision\"] = p\n",
    "        val_metrics[f\"val_recall\"] = r\n",
    "        val_metrics[f\"val_f1_score\"] = f\n",
    "        self.logger.log_metrics(val_metrics)\n",
    "        self.metrics[\"val\"].append(val_metrics)\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        preds = []\n",
    "        for x in outputs:\n",
    "            for pred in x[\"preds\"]:\n",
    "                preds.append(pred)\n",
    "\n",
    "        # Log results\n",
    "        od = Path(\"modelData\")\n",
    "        # results_file = od / \"test.predictions.csv\"\n",
    "        results_file = od / \"submissions.csv\"\n",
    "\n",
    "        with open(results_file, \"w\") as writer:\n",
    "            writer.write(\"Id,Predicted\\n\")\n",
    "            for xid, x in enumerate(preds):\n",
    "                writer.write(str(xid) + \",\" + str(x) + \"\\n\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "import argparse\n",
    "import random\n",
    "import torch\n",
    "from pathlib import Path\n",
    "import pytorch_lightning as pl\n",
    "from pl_model import RumourDetection\n",
    "from utils import pickle_save\n",
    "from callback import LoggingCallback\n",
    "\n",
    "\n",
    "def add_model_specific_args(parser):\n",
    "    parser.add_argument(\"--learning_rate\", default=5e-5, type=float, help=\"The initial learning rate.\")\n",
    "    parser.add_argument(\"--weight_decay\", default=0.0, type=float, help=\"Weight decay if we apply some.\")\n",
    "    parser.add_argument(\"--num_workers\", default=8, type=int, help=\"kwarg passed to DataLoader\")\n",
    "    parser.add_argument(\"--warmup_ratio\", default=0.1, type=float, help=\"warm up rate steps\")\n",
    "    parser.add_argument(\"--save_top_k\", type=int, default=1, required=False, help=\"How many checkpoints to save\")\n",
    "    parser.add_argument(\"--train_batch_size\", default=32, type=int)\n",
    "    parser.add_argument(\"--eval_batch_size\", default=32, type=int)\n",
    "    parser.add_argument(\"--test_batch_size\", default=32, type=int)\n",
    "\n",
    "    parser.add_argument(\"--seed\", type=int, default=42, help=\"random seed for initialization\")\n",
    "    parser.add_argument(\n",
    "        \"--gradient_accumulation_steps\",\n",
    "        dest=\"accumulate_grad_batches\",\n",
    "        type=int,\n",
    "        default=1,\n",
    "        help=\"Number of updates steps to accumulate before performing a backward/update pass.\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output_dir\",\n",
    "        default=None,\n",
    "        type=str,\n",
    "        required=True,\n",
    "        help=\"The output directory where the model predictions and checkpoints will be written.\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--max_length\",\n",
    "        default=60,\n",
    "        type=int,\n",
    "        help=\"The maximum sentence length after tokenization. Sequences longer \"\n",
    "             \"than this will be truncated, sequences shorter will be padded.\",\n",
    "    )\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--early_stopping_patience\",\n",
    "        type=int,\n",
    "        default=-1,\n",
    "        required=False,\n",
    "        help=\"-1 means never early stop. early_stopping_patience is measured in validation checks, not epochs. So val_check_interval will effect it.\",\n",
    "    )\n",
    "    parser.add_argument(\"--pre_encoder\", default=\"bert-base-uncased\", help=\"pre-trained encoder\")\n",
    "    parser.add_argument(\"--wandb\", action=\"store_true\", default=False, help=\"Whether to use wandb.\")\n",
    "    parser.add_argument(\"--fp16\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--n_train\", type=int, default=-1, required=False, help=\"# examples. -1 means use all.\")\n",
    "    parser.add_argument(\"--n_val\", type=int, default=-1, required=False, help=\"# examples. -1 means use all.\")\n",
    "    parser.add_argument(\"--n_test\", type=int, default=-1, required=False, help=\"# examples. -1 means use all.\")\n",
    "    return parser\n",
    "\n",
    "\n",
    "def train_model(model, args, logger):\n",
    "    # init random seed\n",
    "    pl.seed_everything(args.seed)\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "    # add model checkpoints callback\n",
    "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "        dirpath=args.output_dir, filename=\"{f1_score:.4f}\", monitor=\"f1_score\", mode=\"max\", save_top_k=args.save_top_k\n",
    "    )\n",
    "\n",
    "    # add logging callback\n",
    "    logging_callback = LoggingCallback()\n",
    "    # lr_monitor = pl.callbacks.LearningRateMonitor(logging_interval='step')\n",
    "    extra_callbacks = [logging_callback, checkpoint_callback]\n",
    "    # add early stop callback\n",
    "    if args.early_stopping_patience > 0:\n",
    "        early_stopping_callback = pl.callbacks.EarlyStopping(\n",
    "            monitor=\"f1_score\",\n",
    "            mode=\"max\",\n",
    "            patience=args.early_stopping_patience,\n",
    "            verbose=True,\n",
    "        )\n",
    "        extra_callbacks.append(early_stopping_callback)\n",
    "\n",
    "    if args.fp16:\n",
    "        precision = 16\n",
    "    else:\n",
    "        precision = 32\n",
    "\n",
    "    trainer = pl.Trainer.from_argparse_args(\n",
    "        args,\n",
    "        weights_summary=\"top\",\n",
    "        callbacks=extra_callbacks,\n",
    "        logger=logger,\n",
    "        precision=precision,\n",
    "    )\n",
    "\n",
    "    trainer.fit(model)\n",
    "\n",
    "    return trainer\n",
    "\n",
    "\n",
    "def main(args):\n",
    "    odir = Path(args.output_dir)\n",
    "    odir.mkdir(exist_ok=True)\n",
    "\n",
    "    # init model\n",
    "    model = RumourDetection(args)\n",
    "\n",
    "    # init logger\n",
    "    if args.wandb:\n",
    "        from pytorch_lightning.loggers import WandbLogger\n",
    "        logger = WandbLogger(name=\"twitter\", project=\"NLP\")\n",
    "    else:\n",
    "        logger = True\n",
    "\n",
    "    trainer = train_model(model, args, logger)\n",
    "\n",
    "    pickle_save(model.hparams, model.hparams_save_path)\n",
    "    trainer.test(verbose=False, ckpt_path=\"best\")\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser = pl.Trainer.add_argparse_args(parser)\n",
    "    parser = add_model_specific_args(parser)\n",
    "    args = parser.parse_args()\n",
    "    main(args)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}